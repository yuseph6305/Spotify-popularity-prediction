{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Spotify Song Popularity Prediction\n\nThis project explores what makes a song popular on Spotify. The goal is to predict a track\u2019s popularity score (0\u2013100) using its audio features such as energy, danceability, tempo, and valence.\n\nThe dataset comes from the public **Spotify Tracks Database** on Kaggle. This analysis follows a typical data science workflow \u2014 data cleaning, exploration, model building, evaluation, and reflection.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd, numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "try:\n",
        "    from xgboost import XGBRegressor\n",
        "    HAS_XGB = True\n",
        "except Exception:\n",
        "    HAS_XGB = False\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (7,4)\n",
        "pd.set_option('display.max_columns', 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "PATH = 'data/spotify_tracks.csv'  # <- replace if needed\n",
        "df_raw = pd.read_csv(PATH)\n",
        "df_raw.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load and Prepare the Data\n\nThe first step is to load the dataset and select the relevant numerical audio features, along with the target column `popularity`. I\u2019ll also handle missing values and remove extreme outliers to ensure cleaner training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "NUMERIC_FEATURES = ['danceability','energy','loudness','speechiness','acousticness',\n",
        "                     'instrumentalness','liveness','valence','tempo','duration_ms']\n",
        "TARGET_COL = 'popularity'\n",
        "\n",
        "df = df_raw.copy()\n",
        "cols = [c for c in NUMERIC_FEATURES if c in df.columns] + [TARGET_COL]\n",
        "df = df[cols].dropna()\n",
        "df = df[(df['popularity']>=0) & (df['popularity']<=100)]\n",
        "df['tempo'] = df['tempo'].clip(30,220)\n",
        "df['loudness'] = df['loudness'].clip(-60,5)\n",
        "df.describe(include='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Explore the Data (EDA)\n\nBefore building any model, it\u2019s important to understand the relationships between features and popularity. In this step, I\u2019ll explore correlations and visualize how variables like energy, tempo, and danceability relate to popularity.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation with popularity\n",
        "corr = df.corr(numeric_only=True)['popularity'].sort_values(ascending=False)\n",
        "corr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pairwise scatter vs popularity (a few)\n",
        "cols_to_plot = ['danceability','energy','valence','tempo','loudness']\n",
        "for c in cols_to_plot:\n",
        "    plt.figure()\n",
        "    plt.scatter(df[c], df['popularity'], alpha=0.3)\n",
        "    plt.xlabel(c); plt.ylabel('popularity'); plt.title(f'{c} vs popularity')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Split Data for Training and Testing\n\nTo properly evaluate model performance, I\u2019ll split the data into training and test sets. This ensures that the model is tested on unseen data and gives a realistic view of how it might perform in the real world.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df.drop(columns=[TARGET_COL])\n",
        "y = df[TARGET_COL]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Build and Compare Regression Models\n\nNext, I\u2019ll train multiple regression models \u2014 Linear Regression, Ridge, Lasso, Random Forest, and XGBoost. The goal is to see which one best captures the relationship between audio features and popularity.\n\nI\u2019ll use cross-validation and grid search to tune hyperparameters for fair comparison.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models = {\n",
        "    'linreg': Pipeline([('scaler', StandardScaler()), ('model', LinearRegression())]),\n",
        "    'ridge':  Pipeline([('scaler', StandardScaler()), ('model', Ridge())]),\n",
        "    'lasso':  Pipeline([('scaler', StandardScaler()), ('model', Lasso(max_iter=5000))]),\n",
        "    'rf':     Pipeline([('model', RandomForestRegressor(random_state=42))])\n",
        "}\n",
        "if HAS_XGB:\n",
        "    models['xgb'] = Pipeline([('model', XGBRegressor(random_state=42, n_estimators=300, learning_rate=0.05,\n",
        "                                                     max_depth=6, subsample=0.8, colsample_bytree=0.8))])\n",
        "\n",
        "param_grids = {\n",
        "    'ridge': {'model__alpha':[0.1,1.0,3.0,10.0]},\n",
        "    'lasso': {'model__alpha':[0.001,0.01,0.1,1.0]},\n",
        "    'rf':    {'model__n_estimators':[200,400],\n",
        "              'model__max_depth':[None,10,20],\n",
        "              'model__min_samples_split':[2,5]}\n",
        "}\n",
        "if 'xgb' in models:\n",
        "    param_grids['xgb'] = {'model__n_estimators':[200,400],\n",
        "                          'model__max_depth':[4,6,8],\n",
        "                          'model__learning_rate':[0.03,0.05,0.1]}\n",
        "\n",
        "def eval_metrics(y_true, y_pred):\n",
        "    return {\n",
        "        'RMSE': mean_squared_error(y_true, y_pred, squared=False),\n",
        "        'MAE': mean_absolute_error(y_true, y_pred),\n",
        "        'R2': r2_score(y_true, y_pred)\n",
        "    }\n",
        "\n",
        "results = {}\n",
        "best_name, best_model, best_r2 = None, None, -np.inf\n",
        "\n",
        "for name, pipe in models.items():\n",
        "    if name in param_grids:\n",
        "        gs = GridSearchCV(pipe, param_grids[name], scoring='r2', cv=5, n_jobs=-1)\n",
        "        gs.fit(X_train, y_train)\n",
        "        model = gs.best_estimator_\n",
        "    else:\n",
        "        pipe.fit(X_train, y_train)\n",
        "        model = pipe\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    metrics = eval_metrics(y_test, y_pred)\n",
        "    results[name] = metrics\n",
        "    if metrics['R2'] > best_r2:\n",
        "        best_name, best_model, best_r2 = name, model, metrics['R2']\n",
        "\n",
        "results, best_name, best_r2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Visualize Predictions vs Actual Values\n\nThis scatter plot compares the predicted popularity scores against the true values from the test set. A perfect model would produce points close to the diagonal line \u2014 meaning its predictions are accurate.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = best_model.predict(X_test)\n",
        "plt.figure()\n",
        "plt.scatter(y_test, y_pred, alpha=0.4)\n",
        "plt.xlabel('Actual popularity')\n",
        "plt.ylabel('Predicted popularity')\n",
        "plt.title(f'Predicted vs Actual ({best_name})')\n",
        "plt.plot([0,100],[0,100])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Interpret Feature Importance\n\nUnderstanding which audio features influence popularity is key. This section examines the most important predictors according to the best-performing model. It helps explain what aspects of a song tend to make it popular.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "feat_names = list(X.columns)\n",
        "\n",
        "if hasattr(best_model[-1], 'feature_importances_'):\n",
        "    importances = best_model[-1].feature_importances_\n",
        "    order = np.argsort(importances)[::-1]\n",
        "    for idx in order:\n",
        "        print(f\"{feat_names[idx]}: {importances[idx]:.4f}\")\n",
        "elif hasattr(best_model[-1], 'coef_'):\n",
        "    coefs = best_model[-1].coef_\n",
        "    if coefs.ndim == 1:\n",
        "        order = np.argsort(np.abs(coefs))[::-1]\n",
        "        for idx in order:\n",
        "            print(f\"{feat_names[idx]}: {coefs[idx]:.4f}\")\n",
        "else:\n",
        "    print('Model does not expose feature importances or coefficients.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Save the Best Model\n\nFinally, I\u2019ll save the best-performing model as a `.pkl` file so it can be reused later in a web app or API without retraining. This step simulates how machine learning models are deployed in real-world applications.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib, os\n",
        "os.makedirs('models', exist_ok=True)\n",
        "joblib.dump(best_model, 'models/final_model.pkl')\n",
        "'Model saved to models/final_model.pkl'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Conclusion and Reflection\n\nIn this project, I built several regression models to predict Spotify song popularity from audio features. Random Forest and XGBoost generally performed the best, suggesting that non-linear patterns play a strong role in music popularity.\n\n**Key insights:**\n\n- Energy, valence, and danceability were strong predictors of popularity.\n\n- Simpler models like linear regression underfit the data, missing complex interactions.\n\n- Data preprocessing and feature scaling significantly affected performance.\n\nIf I were to extend this project, I would include text data such as lyrics or user reviews, or incorporate time-based features like release year and genre trends.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}